{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the APY-GZSL dataset into ZSL format\n",
    "\n",
    "This notebook is used to split the APY dataset into training and validation classes, as required for evaluation in the ZSL scenario. The splits used were taken from [this paper](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/zero-shot-learning/zero-shot-learning-the-good-the-bad-and-the-ugly/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the separation\n",
    "\n",
    "dataset1 ='./Data/APY/train/'\n",
    "dataset2 ='./Data/APY/test/'\n",
    "\n",
    "trainval_classes_file ='./Data/APY/trainvalclasses.txt'\n",
    "test_classes_file ='./Data/APY/testclasses.txt'\n",
    "\n",
    "new_dataset_folder = './Data/APY_Zero'\n",
    "new_trainval_folder_name = './Data/APY_Zero/train/'\n",
    "new_test_folder_name = './Data/APY_Zero/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(new_trainval_folder_name):\n",
    "    os.mkdir(new_trainval_folder_name)\n",
    "\n",
    "if not os.path.exists(new_test_folder_name):\n",
    "    os.mkdir(new_test_folder_name)\n",
    "    \n",
    "if not os.path.exists(new_dataset_folder):\n",
    "    os.mkdir(new_dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load both train and test sets for APY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "irevnet_im_embeddings = pd.concat([pd.read_csv(dataset1 + 'irevnet_image_embeddings.txt', index_col=0, header=0),\n",
    "                                   pd.read_csv(dataset2 + 'irevnet_image_embeddings.txt', index_col=0, header=0)])\n",
    "\n",
    "files_labels = pd.concat([pd.read_csv(dataset1+'filenames_labels.txt', index_col=0, header=0),\n",
    "                          pd.read_csv(dataset2+'filenames_labels.txt', index_col=0, header=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_csv(dataset1+'classes.txt', index_col=0, header=0)\n",
    "\n",
    "trainval_classes = pd.read_csv(trainval_classes_file, header=None)\n",
    "test_classes = pd.read_csv(test_classes_file, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate Image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_of_interest = trainval_classes\n",
    "\n",
    "row_oi = []\n",
    "for class_of_interest in classes_of_interest.iloc[:, 0].values:\n",
    "    class_id = classes.loc[classes['label'] == class_of_interest].index.tolist()[0]\n",
    "    class_row_ids = files_labels.loc[files_labels['class_id'] == class_id].index.tolist()\n",
    "    row_oi.append(class_row_ids)\n",
    "\n",
    "row_ids = [item for sublist in row_oi for item in sublist]  # flatten list of\n",
    "row_ids.sort()\n",
    "\n",
    "new_im_emb = irevnet_im_embeddings.iloc[row_ids, :]\n",
    "new_im_emb.index = range(new_im_emb.shape[0])\n",
    "new_im_emb.index.name = 'sample_id'\n",
    "new_im_emb.to_csv(new_trainval_folder_name + 'irevnet_image_embeddings.txt')\n",
    "\n",
    "new_file_labels = files_labels.iloc[row_ids, :]\n",
    "new_file_labels.index = range(new_file_labels.shape[0])\n",
    "new_file_labels.index.name = 'sample_id'\n",
    "new_file_labels.to_csv(new_trainval_folder_name + 'filenames_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_of_interest = test_classes\n",
    "\n",
    "row_oi = []\n",
    "for class_of_interest in classes_of_interest.iloc[:, 0].values:\n",
    "    class_id = classes.loc[classes['label'] == class_of_interest].index.tolist()[0]\n",
    "    class_row_ids = files_labels.loc[files_labels['class_id'] == class_id].index.tolist()\n",
    "    row_oi.append(class_row_ids)\n",
    "\n",
    "row_ids = [item for sublist in row_oi for item in sublist]  # flatten list of\n",
    "row_ids.sort()\n",
    "\n",
    "new_im_emb = irevnet_im_embeddings.iloc[row_ids, :]\n",
    "new_im_emb.index = range(new_im_emb.shape[0])\n",
    "new_im_emb.index.name = 'sample_id'\n",
    "new_im_emb.to_csv(new_test_folder_name + 'irevnet_image_embeddings.txt')\n",
    "\n",
    "new_file_labels = files_labels.iloc[row_ids, :]\n",
    "new_file_labels.index = range(new_file_labels.shape[0])\n",
    "new_file_labels.index.name = 'sample_id'\n",
    "new_file_labels.to_csv(new_test_folder_name + 'filenames_labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy the rest of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(dataset1+'classes.txt', new_trainval_folder_name+'classes.txt')\n",
    "shutil.copyfile(dataset1+'classes.txt', new_test_folder_name+'classes.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(dataset1+'glove_embeddings_300.txt', new_trainval_folder_name+'glove_embeddings_300.txt')\n",
    "shutil.copyfile(dataset1+'glove_embeddings_300.txt', new_test_folder_name+'glove_embeddings_300.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(dataset1+'class_predicates.txt', new_trainval_folder_name+'class_predicates.txt')\n",
    "shutil.copyfile(dataset1+'class_predicates.txt', new_test_folder_name+'class_predicates.txt');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
