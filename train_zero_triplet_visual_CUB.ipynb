{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZSL modification of original training code\n",
    "\n",
    "This code should be used for ZSL only, not for the generalized ZSL scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from zsldataset import ZSLDataset\n",
    "from models import ContinuousMap, ContinuousMapResidual\n",
    "\n",
    "def dist_matrix(batch1, batch2):\n",
    "    delta = batch1.unsqueeze(1) - batch2.unsqueeze(0)\n",
    "    \n",
    "    dist_matrix = (delta * delta).mean(dim=-1)\n",
    "    \n",
    "    return dist_matrix\n",
    "\n",
    "\n",
    "def mag(u):\n",
    "    return torch.dot(u, u)\n",
    "\n",
    "\n",
    "def dist(u, v):\n",
    "    return torch.dot(u - v, u - v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import EncoderAttributes, DecoderAttributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feature(data):\n",
    "    mean = data.mean(0)\n",
    "    std = data.var(0)\n",
    "    if std > 0:\n",
    "        return (data - mean) / std\n",
    "    else:\n",
    "        return (data - mean) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ZSLDataset('Data/CUB/train_set', use_predicates=True, use_irevnet=False)\n",
    "testset = ZSLDataset('Data/CUB/test_set', use_predicates=True, use_irevnet=False)\n",
    "\n",
    "\n",
    "\n",
    "#trainset.image_embeddings = normalize_feature(trainset.image_embeddings)\n",
    "#testset.image_embeddings = normalize_feature(testset.image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = 32\n",
    "n_epochs = 200\n",
    "num_classes = trainset.classes.shape[0]\n",
    "\n",
    "dim_semantic = trainset[0]['class_embedding'].shape[0]\n",
    "dim_visual = trainset[0]['image_embedding'].shape[0]\n",
    "dim_attributes = trainset[0]['class_predicates'].shape[0]\n",
    "\n",
    "all_class_embeddings = torch.tensor(np.array(trainset.class_embeddings)).cuda().float()\n",
    "all_train_image_embeddings = torch.tensor(np.array(trainset.image_embeddings)).cuda().float()\n",
    "all_train_labels = torch.tensor(trainset.labels['class_id'].values).cuda() - 1\n",
    "all_class_predicates = torch.tensor(np.array(trainset.class_predicates)).cuda().float()\n",
    "classes_enum = torch.tensor(np.array(range(num_classes), dtype=np.int64)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_classes = set([testset[i]['class_label'] for i in range(len(testset))])\n",
    "query_ids = set([testset[i]['class_id'] for i in range(len(testset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(i-1 for i in query_ids)\n",
    "query_mask = np.zeros((num_classes))\n",
    "query_mask[ids] = 1\n",
    "query_mask = torch.tensor(query_mask, dtype=torch.int64).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_to_s = DecoderAttributes(dim_source=dim_visual, dim_target1=dim_attributes, dim_target2=dim_semantic, width=512).cuda()\n",
    "s_to_v = EncoderAttributes(dim_source1=dim_semantic, dim_source2=dim_attributes, dim_target=dim_visual, width=512).cuda()\n",
    "\n",
    "# optimizer = torch.optim.Adam(list(v_to_s.parameters()) + list(s_to_v.parameters()),\n",
    "#                                 lr = 1e-3,\n",
    "#                                 betas=(0.9, 0.999),\n",
    "#                                 weight_decay=3e-2)\n",
    "\n",
    "optimizer = torch.optim.SGD(list(v_to_s.parameters()) + list(s_to_v.parameters()),\n",
    "                                lr = 5e-4,\n",
    "                                momentum=.5,\n",
    "                                nesterov=True,\n",
    "                                weight_decay=3e-2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss()\n",
    "triplet_loss = torch.nn.TripletMarginLoss(margin=1, p=2)\n",
    "positive_part = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                             batch_size=bsize, \n",
    "                                             shuffle=True, \n",
    "                                             num_workers=4, \n",
    "                                             pin_memory=True, \n",
    "                                             drop_last=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, \n",
    "                                         batch_size=bsize, \n",
    "                                         shuffle=True, \n",
    "                                         num_workers=4, \n",
    "                                         pin_memory=True, \n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1\n",
    "\n",
    "alpha1 = 50 # triplet\n",
    "alpha4 = 50 #triplet visual\n",
    "alpha2 = 5e-3 # surjection\n",
    "alpha3 = 5e-3 # l2 loss\n",
    "\n",
    "margin_s = 0\n",
    "margin_v = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- Evaluation on epoch 0\n",
      "Average acc.: 0.04042119565217391, Average loss:4043.613354226817\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Evaluation on epoch 1\n",
      "Average acc.: 0.030570652173913044, Average loss:3572.493896484375\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Evaluation on epoch 2\n",
      "Average acc.: 0.030400815217391304, Average loss:3234.5476472274117\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Evaluation on epoch 3\n",
      "Average acc.: 0.026834239130434784, Average loss:3271.6826556661854\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(n_epochs):\n",
    "    v_to_s = v_to_s.train()\n",
    "    s_to_v = s_to_v.train()\n",
    "    \n",
    "    for i, sample in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_visual = sample['image_embedding'].cuda().float()\n",
    "        batch_semantic = sample['class_embedding'].cuda().float()\n",
    "        batch_predicates = sample['class_predicates'].cuda().float()\n",
    "        batch_classes = sample['class_id'].cuda() - 1\n",
    "         \n",
    "        e_hat = v_to_s(s_to_v(all_class_embeddings, all_class_predicates))\n",
    "        delta = (e_hat[1] - all_class_embeddings)\n",
    "        surjection_loss = (delta * delta).sum(dim=-1).mean()\n",
    "        delta = (e_hat[0] - all_class_predicates)\n",
    "        surjection_loss = (1-gamma) * surjection_loss + gamma * (delta * delta).sum(dim=-1).mean()\n",
    "        \n",
    "        s_out = v_to_s(batch_visual)\n",
    "        s_attr, s_word = s_out\n",
    "        \n",
    "        \n",
    "        \n",
    "        same_class = classes_enum.unsqueeze(0) == batch_classes.unsqueeze(1)\n",
    "        same_class = same_class.detach()\n",
    "        \n",
    "        ##Triplet loss in semantic space\n",
    "        d_matrix_s = (1 - gamma) * dist_matrix(s_word, all_class_embeddings) + \\\n",
    "                    gamma * dist_matrix(s_attr, all_class_predicates)\n",
    "        \n",
    "        \n",
    "        \n",
    "        closest_negative_s, _ = (d_matrix_s + same_class.float() * 1e6).min(dim=-1)\n",
    "        furthest_positive_s, _ = (d_matrix_s * same_class.float()).max(dim=-1)\n",
    "        \n",
    "        l2_loss_s = (1-gamma) * (s_word * s_word).sum(dim=-1).mean() + \\\n",
    "                    gamma * (s_attr * s_attr).sum(dim=-1).mean()\n",
    "\n",
    "        trip_loss_s = positive_part(furthest_positive_s - closest_negative_s + margin_s)\n",
    "        \n",
    "        \n",
    "        ##Triplet loss in visual space\n",
    "        same_class = all_train_labels.unsqueeze(0) == batch_classes.unsqueeze(1)\n",
    "        same_class = same_class.detach()\n",
    "        v_out = s_to_v(batch_semantic, batch_predicates)\n",
    "        d_matrix_v =  dist_matrix(v_out,all_train_image_embeddings)\n",
    "        \n",
    "        closest_negative_v, _ = (d_matrix_v + same_class.float() * 1e6).min(dim=-1)\n",
    "        \n",
    "        furthest_positive_v, _ = (d_matrix_v * same_class.float()).max(dim=-1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        l2_loss_v = (1-gamma) * (v_out * v_out).sum(dim=-1).mean() \n",
    "        \n",
    "\n",
    "        trip_loss_v = positive_part(furthest_positive_v - closest_negative_v + margin_v)\n",
    "        \n",
    "        ##Total loss\n",
    "        \n",
    "        loss = alpha1 * trip_loss_s.mean() + alpha2 * surjection_loss + alpha3 * l2_loss_s  + alpha4 * trip_loss_v.mean() + alpha3 * l2_loss_v \n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #print( trip_loss_s.mean(),l2_loss_s,trip_loss_v.mean(),l2_loss_v, surjection_loss)\n",
    "        \n",
    "#         c_hat = d_matrix.argmin(dim = -1)\n",
    "#         print((c_hat == batch_classes).float().mean().item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "       # print(loss.item(), end=', ')\n",
    "        \n",
    "    if (e+1) % 20 == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.7\n",
    "            \n",
    "    \n",
    "    if (e+1) % 1 == 0:\n",
    "        print('\\n\\n- Evaluation on epoch {}'.format(e))\n",
    "        \n",
    "        avg_accuracy = 0.\n",
    "        avg_loss = 0.\n",
    "        n = 0\n",
    "        \n",
    "        v_to_s = v_to_s.eval() \n",
    "        s_to_v = s_to_v.eval() \n",
    "        \n",
    "        v_out = s_to_v(all_class_embeddings, all_class_predicates)\n",
    "        with torch.no_grad():\n",
    "            for i, sample in enumerate(testloader):\n",
    "                n += 1\n",
    "                \n",
    "                batch_visual = sample['image_embedding'].cuda().float()\n",
    "                #batch_semantic = sample['class_embedding'].cuda().float()\n",
    "\n",
    "                batch_classes = sample['class_id'].cuda() - 1\n",
    "\n",
    "                s_out = v_to_s(batch_visual)\n",
    "                s_attr, s_word = s_out\n",
    "                \n",
    "                \n",
    "                \n",
    "                same_class = classes_enum.unsqueeze(0) == batch_classes.unsqueeze(1)\n",
    "                same_class = same_class.detach()\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                ##Triplet loss in semantic space\n",
    "                d_matrix_s = (1 - gamma) * dist_matrix(s_word, all_class_embeddings) + \\\n",
    "                            gamma * dist_matrix(s_attr, all_class_predicates)\n",
    "\n",
    "                 \n",
    "\n",
    "                closest_negative_s, _ = (d_matrix_s + same_class.float() * 1e6).min(dim=-1)\n",
    "                furthest_positive_s, _ = (d_matrix_s * same_class.float()).max(dim=-1)\n",
    "\n",
    "                l2_loss_s = (1-gamma) * (s_word * s_word).sum(dim=-1).mean() + \\\n",
    "                            gamma * (s_attr * s_attr).sum(dim=-1).mean()\n",
    "\n",
    "                trip_loss_s = positive_part(furthest_positive_s - closest_negative_s + margin_s)\n",
    "\n",
    "\n",
    "                ##Triplet loss in visual space\n",
    "                \n",
    "                d_matrix_v =  dist_matrix(batch_visual,v_out)\n",
    "                same_class = classes_enum.unsqueeze(0) == batch_classes.unsqueeze(1) \n",
    "                same_class = same_class.detach()\n",
    "\n",
    "\n",
    "                closest_negative_v, _ = (d_matrix_v + same_class.float() * 1e6).min(dim=-1)\n",
    "                furthest_positive_v, _ = (d_matrix_v * same_class.float()).max(dim=-1)\n",
    "                c_hat = (d_matrix_v + (1 - query_mask).float() * 1e9).argmin(dim = -1)\n",
    "                \n",
    "                l2_loss_v = (1-gamma) * (v_out * v_out).sum(dim=-1).mean() \n",
    "\n",
    "                trip_loss_v = positive_part(furthest_positive_v - closest_negative_v + margin_v)\n",
    "                \n",
    "\n",
    "                ##Total loss\n",
    "                loss = alpha1 * trip_loss_s.mean() + alpha2 * surjection_loss + alpha3 * l2_loss_s + alpha4 * trip_loss_v.mean()  + alpha3 * l2_loss_v\n",
    "                #loss = alpha1*trip_loss_v.mean() +  alpha3 * l2_loss_v\n",
    "\n",
    "                avg_loss += loss.item()\n",
    "                #print(c_hat)\n",
    "                #print(batch_visual)\n",
    "                #print(batch_classes)\n",
    "                avg_accuracy += (c_hat == batch_classes).float().mean().item()\n",
    "\n",
    "        avg_accuracy /= n\n",
    "        avg_loss /= n\n",
    "\n",
    "        print('Average acc.: {}, Average loss:{}\\n\\n'.format(avg_accuracy, avg_loss))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
