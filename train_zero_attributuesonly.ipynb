{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZSL training - with attributes only\n",
    "\n",
    "This code should be used for ZSL only, not for the generalized ZSL scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from zsldataset import ZSLDataset\n",
    "from models import ContinuousMap, ContinuousMapResidual\n",
    "\n",
    "def dist_matrix(batch1, batch2):\n",
    "    delta = batch1.unsqueeze(1) - batch2.unsqueeze(0)\n",
    "    \n",
    "    dist_matrix = (delta * delta).mean(dim=-1)\n",
    "    \n",
    "    return dist_matrix\n",
    "\n",
    "\n",
    "def mag(u):\n",
    "    return torch.dot(u, u)\n",
    "\n",
    "\n",
    "def dist(u, v):\n",
    "    return torch.dot(u - v, u - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load APY dataset\n",
    "\n",
    "Should be converted into ZSL format beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = ZSLDataset('Data/APY_Zero/train', use_predicates=True, use_irevnet=True)    ############# changed this line\n",
    "testset = ZSLDataset('Data/APY_Zero/test', use_predicates=True, use_irevnet=True)    ############# changed this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = 128\n",
    "n_epochs = 200\n",
    "num_classes = trainset.classes.shape[0]\n",
    "\n",
    "dim_semantic = trainset[0]['class_predicates'].shape[0]   ############# changed this line\n",
    "dim_visual = trainset[0]['image_embedding'].shape[0]  ############# changed this line\n",
    "\n",
    "all_class_embeddings = torch.tensor(np.array(trainset.class_predicates)).cuda().float()  ############# changed this line\n",
    "\n",
    "classes_enum = torch.tensor(np.array(range(num_classes), dtype=np.int64)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_classes = set([testset[i]['class_label'] for i in range(len(testset))])\n",
    "query_ids = set([testset[i]['class_id'] for i in range(len(testset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(i-1 for i in query_ids)\n",
    "query_mask = np.zeros((num_classes))\n",
    "query_mask[ids] = 1\n",
    "query_mask = torch.tensor(query_mask, dtype=torch.int64).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_to_s = ContinuousMap(dim_source=dim_visual, dim_dest=dim_semantic, width=512).cuda()\n",
    "s_to_v = ContinuousMap(dim_source=dim_semantic, dim_dest=dim_visual, width=512).cuda()\n",
    "\n",
    "# optimizer = torch.optim.Adam(list(v_to_s.parameters()) + list(s_to_v.parameters()),\n",
    "#                                 lr = 1e-3,\n",
    "#                                 betas=(0.9, 0.999),\n",
    "#                                 weight_decay=3e-2)\n",
    "\n",
    "optimizer = torch.optim.SGD(list(v_to_s.parameters()) + list(s_to_v.parameters()),\n",
    "                                lr = 1e-4,\n",
    "                                momentum=.9,\n",
    "                                weight_decay=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss()\n",
    "positive_part = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                             batch_size=bsize, \n",
    "                                             shuffle=True, \n",
    "                                             num_workers=4, \n",
    "                                             pin_memory=True, \n",
    "                                             drop_last=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, \n",
    "                                         batch_size=bsize, \n",
    "                                         shuffle=True, \n",
    "                                         num_workers=4, \n",
    "                                         pin_memory=True, \n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[1]['class_predicates'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = 20 # triplet\n",
    "alpha2 = 1e-2 # surjection\n",
    "alpha3 = 1e-3 # l2 loss\n",
    "\n",
    "alpha_backward = 1e-2\n",
    "\n",
    "margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for e in range(n_epochs):\n",
    "    v_to_s = v_to_s.train()\n",
    "    s_to_v = s_to_v.train()\n",
    "    \n",
    "    for i, sample in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_visual = sample['image_embedding'].cuda().float()  ############# changed this line\n",
    "        batch_semantic = sample['class_predicates'].cuda().float() ############# changed this line\n",
    "\n",
    "        batch_classes = sample['class_id'].cuda() - 1\n",
    "        \n",
    "        backward_v = s_to_v(all_class_embeddings)\n",
    "        e_hat = v_to_s(backward_v)\n",
    "        delta = (e_hat - all_class_embeddings)\n",
    "        surjection_loss = (delta * delta).sum(dim=-1).mean()\n",
    "        \n",
    "        s_out = v_to_s(batch_visual)\n",
    "        \n",
    "        same_class = classes_enum.unsqueeze(0) == batch_classes.unsqueeze(1)\n",
    "        same_class = same_class.detach()\n",
    "\n",
    "        d_matrix = dist_matrix(s_out, all_class_embeddings)\n",
    "\n",
    "        closest_negative, _ = (d_matrix + same_class.float() * 1e6).min(dim=-1)\n",
    "        furthest_positive, _ = (d_matrix * same_class.float()).max(dim=-1)\n",
    "        \n",
    "        l2_loss = (s_out * s_out).sum(dim=-1).mean()\n",
    "\n",
    "        loss = positive_part(furthest_positive - closest_negative + margin)\n",
    "        \n",
    "        backwards_l2_loss = (backward_v * backward_v).sum(dim=-1).mean()\n",
    "        \n",
    "        loss = alpha1 * loss.mean() + alpha2 * surjection_loss + \\\n",
    "                alpha3 * l2_loss + alpha_backward * backwards_l2_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "#         c_hat = d_matrix.argmin(dim = -1)\n",
    "#         print((c_hat == batch_classes).float().mean().item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print(loss.item(), end=', ')\n",
    "        \n",
    "    if (e+1) % 50 == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.7\n",
    "    \n",
    "    if (e+1) % 5 == 0:\n",
    "        print('\\n\\n- Evaluation on epoch {}'.format(e))\n",
    "        \n",
    "        avg_accuracy = 0.\n",
    "        avg_loss = 0.\n",
    "        n = 0\n",
    "        \n",
    "        v_to_s = v_to_s.eval() \n",
    "        s_to_v = s_to_v.eval() \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, sample in enumerate(testloader):\n",
    "                n += 1\n",
    "                \n",
    "                batch_visual = sample['image_embedding'].cuda().float()  ############# changed this line\n",
    "                batch_semantic = sample['class_predicates'].cuda().float()   ############# changed this line\n",
    "\n",
    "                batch_classes = sample['class_id'].cuda() - 1\n",
    "\n",
    "                s_out = v_to_s(batch_visual)\n",
    "\n",
    "                same_class = classes_enum.unsqueeze(0) == batch_classes.unsqueeze(1)\n",
    "                same_class = same_class.detach()\n",
    "\n",
    "                d_matrix = dist_matrix(s_out, all_class_embeddings) \n",
    "                \n",
    "                c_hat = (d_matrix + (1 - query_mask).float() * 1e6).argmin(dim = -1)\n",
    "\n",
    "                closest_negative, _ = (d_matrix + same_class.float() * 1e6).min(dim=-1)\n",
    "                furthest_positive, _ = (d_matrix * same_class.float()).max(dim=-1)\n",
    "\n",
    "                loss = positive_part(furthest_positive - closest_negative + margin)\n",
    "                loss = alpha1 * furthest_positive.mean()\n",
    "\n",
    "                avg_loss += loss.item()\n",
    "                avg_accuracy += (c_hat == batch_classes).float().mean().item()\n",
    "\n",
    "        avg_accuracy /= n\n",
    "        avg_loss /= n\n",
    "\n",
    "        print('Average acc.: {}, Average loss:{}\\n\\n'.format(avg_accuracy, avg_loss))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.862548828125, 23.815404891967773, 23.87175178527832, 23.79213523864746, 23.81304168701172, 23.843965530395508, 23.90216064453125, 23.825401306152344, 23.826231002807617, 23.902111053466797, 23.654884338378906, 23.871702194213867, 23.78680419921875, 23.792404174804688, 23.690378189086914, 23.803163528442383, 23.679607391357422, 23.83673095703125, 23.785581588745117, 23.769989013671875, 23.691364288330078, 23.722431182861328, 23.625415802001953, 23.61703872680664, 23.649789810180664, 23.626506805419922, 23.6696834564209, 23.739299774169922, 23.75798225402832, 23.617061614990234, 23.67873764038086, 23.60660743713379, 23.675582885742188, 23.667987823486328, 23.67871856689453, 23.630874633789062, 23.66771697998047, 23.437854766845703, 23.480878829956055, 23.533554077148438, 23.536422729492188, 23.59556770324707, 23.407636642456055, 23.632667541503906, 23.532798767089844, 23.514942169189453, 23.474397659301758, 23.505352020263672, 23.539169311523438, 23.5230770111084, 23.378650665283203, 23.49990463256836, 23.53278160095215, 23.472349166870117, 23.44844627380371, 23.366662979125977, 23.440670013427734, 23.4002742767334, 23.396883010864258, 23.425193786621094, 23.32248306274414, 23.205812454223633, 23.270904541015625, 23.23051643371582, 23.160030364990234, 23.245651245117188, 23.346267700195312, 23.29271125793457, 23.458995819091797, 23.238513946533203, 23.07207679748535, 23.12667465209961, 23.377466201782227, 23.17146873474121, 23.109294891357422, 23.131208419799805, 23.244651794433594, 23.14659881591797, 23.134401321411133, 22.933448791503906, 22.931543350219727, 22.90868377685547, 22.85472297668457, 23.22509765625, 23.28467559814453, 23.070215225219727, 22.872316360473633, 22.832748413085938, 22.974225997924805, 22.803176879882812, 22.787025451660156, 22.865562438964844, 23.00702476501465, 23.15999412536621, 23.16232681274414, 22.85553550720215, 23.21145248413086, 22.92409896850586, 22.928234100341797, 22.84066390991211, 22.779605865478516, 22.6417236328125, 22.729389190673828, 22.52500343322754, 22.692874908447266, 22.857711791992188, 22.928224563598633, 22.852901458740234, 22.57023048400879, 22.826318740844727, 22.511245727539062, 22.842613220214844, 22.797359466552734, 22.721012115478516, 22.872365951538086, 22.84709930419922, 22.80755043029785, 22.30860137939453, 22.38907241821289, 22.45308494567871, 22.347736358642578, 23.137859344482422, 22.764463424682617, 22.750802993774414, 22.73578453063965, 22.59136390686035, 22.973966598510742, 22.619083404541016, 22.804515838623047, 22.348369598388672, 22.792022705078125, 22.40570831298828, 22.776208877563477, 22.386432647705078, 22.822566986083984, 22.55577278137207, 22.18868637084961, 22.397171020507812, 22.68278694152832, 22.589414596557617, 22.910043716430664, 22.764942169189453, 22.3198184967041, 22.65800666809082, 22.728038787841797, 22.5988712310791, 21.98944091796875, 22.5297794342041, 22.541854858398438, 22.164941787719727, 22.64910888671875, 22.406251907348633, 23.000465393066406, 22.813796997070312, 22.45551872253418, 22.701557159423828, 21.877017974853516, 22.520002365112305, 22.6580867767334, 22.45863151550293, 22.706113815307617, 22.90839385986328, 22.469688415527344, 22.504589080810547, 22.348432540893555, 22.053007125854492, 22.073406219482422, 22.529163360595703, 22.431814193725586, 22.56341552734375, 22.61774253845215, 22.758201599121094, 21.954708099365234, 22.373937606811523, 22.1964111328125, 22.369457244873047, 22.53199577331543, 22.448415756225586, 22.228099822998047, 22.152748107910156, 22.049541473388672, 22.352008819580078, 22.410146713256836, 22.542055130004883, 21.700502395629883, 21.871248245239258, 22.19556427001953, 22.343551635742188, 22.46698760986328, 22.530040740966797, 22.482263565063477, 22.4681396484375, 22.472043991088867, 22.501855850219727, 22.008962631225586, 22.412206649780273, 22.680971145629883, 22.34429931640625, 22.387592315673828, 21.910411834716797, 22.2706298828125, 21.9901065826416, 22.168838500976562, 22.426795959472656, 22.35030746459961, 22.28467559814453, 22.503095626831055, 22.258031845092773, 22.109296798706055, 22.007728576660156, 22.250957489013672, 22.447731018066406, 21.83981704711914, 22.185693740844727, 22.26200294494629, 22.34890365600586, 21.925634384155273, 22.206626892089844, 22.228710174560547, 21.911588668823242, 21.895824432373047, 22.068941116333008, 22.01410675048828, 22.28382110595703, 22.21226692199707, 22.011781692504883, 21.916553497314453, 22.507282257080078, 22.28924560546875, 21.83892822265625, 22.249950408935547, 21.865171432495117, 21.978967666625977, 22.061241149902344, 21.406362533569336, 22.159154891967773, 21.805227279663086, 21.94162368774414, 22.06794548034668, 21.862165451049805, 22.42741584777832, 22.324951171875, 22.146060943603516, 21.904102325439453, 21.965896606445312, 21.938026428222656, 21.807003021240234, 22.37483787536621, 22.06603240966797, 21.800512313842773, 22.423656463623047, 21.588218688964844, 21.727073669433594, 22.27008819580078, 22.411800384521484, 22.10283088684082, 22.107677459716797, 21.894317626953125, 21.829071044921875, 22.40853500366211, 22.043664932250977, 21.955341339111328, 21.90317153930664, 22.20231056213379, 21.9625244140625, 21.60552215576172, 22.069580078125, 22.01082420349121, 21.737972259521484, 21.897680282592773, 22.0955810546875, 21.746246337890625, 22.496753692626953, 21.996322631835938, 21.92622947692871, 21.673030853271484, 21.548229217529297, 21.99056625366211, 21.452993392944336, 21.967655181884766, 22.097742080688477, 22.47035026550293, 22.00298309326172, 22.009910583496094, 21.670299530029297, \n",
      "\n",
      "- Evaluation on epoch 4\n",
      "Average acc.: 0.4656762295081967, Average loss:2.9904869931643128\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.375022888183594, 21.830097198486328, 21.651351928710938, 22.272605895996094, 22.083925247192383, 21.705820083618164, 22.242271423339844, 22.092472076416016, 21.88823699951172, 21.404460906982422, 21.44552993774414, 21.373497009277344, 21.842273712158203, 21.732500076293945, 22.10805320739746, 21.76866340637207, 21.755037307739258, 21.998559951782227, 21.41439437866211, 21.290443420410156, 21.95783233642578, 21.80103302001953, 21.70794677734375, 21.68015480041504, 21.63582420349121, 21.88988494873047, 21.436307907104492, 21.57554054260254, 21.870912551879883, 22.03746795654297, 22.35259246826172, 21.60399055480957, 21.872312545776367, 22.035673141479492, 22.169734954833984, 21.514421463012695, 21.793155670166016, 21.691490173339844, 21.363887786865234, 21.727468490600586, 21.824199676513672, 21.96822738647461, 21.920059204101562, 21.910356521606445, 21.704769134521484, 21.77998924255371, 21.90180015563965, 21.367172241210938, 21.20092010498047, 20.867389678955078, 21.027761459350586, 21.77600860595703, 21.799470901489258, 21.96588897705078, 21.93723487854004, 21.63813018798828, 21.332592010498047, 21.859481811523438, 21.981586456298828, 21.499160766601562, 21.489248275756836, 21.774669647216797, 21.78656578063965, 21.00187110900879, 21.8095760345459, 21.453659057617188, 21.371294021606445, 21.681716918945312, 22.046052932739258, 21.63762855529785, 20.784534454345703, 21.465482711791992, 21.437236785888672, 21.39405059814453, 21.366342544555664, 21.459087371826172, 21.671039581298828, 21.88534164428711, 21.71495246887207, 21.81149673461914, 21.383407592773438, 21.22135353088379, 21.631643295288086, 21.49626350402832, 21.34294319152832, 20.949966430664062, 21.708423614501953, 21.690418243408203, 21.398183822631836, 21.383840560913086, 21.541746139526367, 21.570140838623047, 21.239702224731445, 21.27971839904785, 21.63672637939453, 21.39314079284668, 21.65709686279297, 21.649272918701172, 21.496265411376953, 21.953201293945312, 21.83098602294922, 21.95897102355957, 21.39354133605957, 21.777713775634766, 21.77596664428711, 21.179868698120117, 21.570283889770508, 21.893293380737305, 21.738311767578125, 21.02381706237793, 21.572263717651367, 21.466228485107422, 21.453876495361328, 21.365989685058594, 21.31420135498047, 21.761213302612305, 21.072952270507812, 21.594684600830078, 21.444726943969727, 20.959434509277344, 21.584609985351562, 20.947023391723633, 21.243175506591797, 21.572006225585938, 21.632387161254883, 21.424434661865234, 21.753957748413086, 21.420272827148438, 21.11318016052246, 21.564659118652344, 21.552461624145508, 20.91086196899414, 20.68044662475586, 21.019939422607422, 21.222768783569336, 21.52066421508789, 21.353073120117188, 21.566452026367188, 21.510107040405273, 21.269651412963867, 21.380382537841797, 21.556249618530273, 20.75210952758789, 21.74676513671875, 21.244457244873047, 21.357622146606445, 21.854921340942383, 21.42151641845703, 21.274669647216797, 21.268878936767578, 21.410823822021484, 20.560813903808594, 21.527517318725586, 21.2812557220459, 21.45926284790039, 21.24660873413086, 21.333251953125, 21.181766510009766, 21.378387451171875, 21.484634399414062, 21.081205368041992, 21.332124710083008, 21.617149353027344, "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}